{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a579e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "#from cityscapesscripts.helpers import labels\n",
    "from cityscapesscripts.helpers import labels as cs_labels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from backbones_unet.model.unet import Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbface0a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1877cf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility is 42\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seeds(SEED)\n",
    "print(f\"Seeds set for reproducibility is {SEED}\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else \"mps\" if torch.mps.is_available() \n",
    "                      else \"cpu\"\n",
    "                    )\n",
    "print(DEVICE)\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import ssl\n",
    "# Disable SSL verification for urllib requests on MacOS\n",
    "# This is a workaround for the \"SSL: CERTIFICATE_VERIFY_FAILED\" error on MacOS\n",
    "@contextmanager\n",
    "def no_ssl_verification():\n",
    "    \"\"\"Temporarily disable SSL verification\"\"\"\n",
    "    old_context = ssl._create_default_https_context\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        ssl._create_default_https_context = old_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d68846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, targets_dir, image_transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (string): Directory with all the images.\n",
    "            targets_dir (string): Directory with all the target masks.\n",
    "            image_transform (callable, optional): Optional transform to be applied on images.\n",
    "            target_transform (callable, optional): Optional transform to be applied on targets.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Get all image filenames\n",
    "        self.image_filenames = [f for f in os.listdir(images_dir) \n",
    "                               if f.lower().endswith(('.png'))]\n",
    "        self.image_filenames.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load target mask\n",
    "        target_name = img_name.replace('.png', '_trainId.png')\n",
    "        target_path = os.path.join(self.targets_dir, target_name)\n",
    "        target = Image.open(target_path)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "       # else:\n",
    "       #     # Default: convert to tensor\n",
    "       #     target = torch.from_numpy(target)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0936a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae5e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds, labels, num_classes, ignore_index=255):\n",
    "    \n",
    "    preds = torch.argmax(preds, dim=1).detach().cpu()  # [B, H, W]\n",
    "    \n",
    "    labels = labels.detach().cpu() \n",
    "    \n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (labels == cls)\n",
    "        \n",
    "        # Escludi pixel ignorati\n",
    "        mask = (labels != ignore_index)\n",
    "        pred_inds = pred_inds & mask\n",
    "        target_inds = target_inds & mask\n",
    "\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        \n",
    "        if union == 0:\n",
    "            continue  # salta classe non presente\n",
    "        ious.append(intersection / union)\n",
    "    \n",
    "    if len(ious) == 0:\n",
    "        return float('nan')  # o 0.0 se preferisci\n",
    "    return sum(ious) / len(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5727ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Clear memory and cache for all device types\"\"\"\n",
    "    # Delete all local variables in the caller's frame\n",
    "    for obj in list(locals().values()):\n",
    "        del obj\n",
    "        \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if DEVICE.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    # Second GC run to make sure everything is cleaned up\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fecbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function\n",
    "def run_test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_iou = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(test_dataloader, desc=\"Testing\")):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)['out']\n",
    "            \n",
    "            # Collect metrics\n",
    "            test_total_iou += compute_iou(outputs.detach().cpu(), masks, NUM_CLASSES)\n",
    "            \n",
    "            # Explicit cleanup\n",
    "            del images, masks, outputs\n",
    "            \n",
    "            # Periodic memory clear\n",
    "            if (i + 1) % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    test_avg_iou = test_total_iou / len(test_dataloader)\n",
    "    return test_avg_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f137c",
   "metadata": {},
   "source": [
    "# DeeplabV3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f7166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"syn_resized_images\"\n",
    "path_target = \"syn_resized_gt\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466)), # We maintain the og aspect ratio\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65a2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f341c",
   "metadata": {},
   "source": [
    "## DeeplabV3 Coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2afe7ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps detected, using no_ssl_verification\n",
      "Loading best model from: models/deeplabv3_resnet50_best_model.pth\n",
      "Best model loaded successfully!\n",
      "Best validation IoU: 0.5830\n",
      "From epoch: 25\n"
     ]
    }
   ],
   "source": [
    "if DEVICE.type == 'mps': \n",
    "    print(\"mps detected, using no_ssl_verification\")\n",
    "    with no_ssl_verification():\n",
    "        model = deeplabv3_resnet50(\n",
    "            weights='COCO_WITH_VOC_LABELS_V1', \n",
    "        )\n",
    "else:\n",
    "    model = deeplabv3_resnet50(\n",
    "        weights='COCO_WITH_VOC_LABELS_V1', \n",
    "    )\n",
    "\n",
    "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "best_model_path = \"models/deeplabv3_resnet50_best_model.pth\"\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Best model loaded successfully!\")\n",
    "print(f\"Best validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "print(f\"From epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e991161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 469/469 [07:14<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Average IoU: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_avg_iou = run_test(model=model,test_dataloader=syn_test_dataloader)\n",
    "print(f\"Test Average IoU: {test_avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fbf7f",
   "metadata": {},
   "source": [
    "## DeeplabV3 Imagenet1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733d3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps detected, using no_ssl_verification\n",
      "Loading best model from: models/deeplabv3_imagenet1k_best_model.pth\n",
      "Best model loaded successfully!\n",
      "Best validation IoU: 0.5857\n",
      "From epoch: 24\n"
     ]
    }
   ],
   "source": [
    "if DEVICE.type == 'mps': \n",
    "    print(\"mps detected, using no_ssl_verification\")\n",
    "    with no_ssl_verification():\n",
    "        model = deeplabv3_resnet50(\n",
    "            weights='COCO_WITH_VOC_LABELS_V1', \n",
    "            weights_backbone='IMAGENET1K_V1'\n",
    "        )\n",
    "else:\n",
    "    model = deeplabv3_resnet50(\n",
    "        weights='COCO_WITH_VOC_LABELS_V1', \n",
    "        weights_backbone='IMAGENET1K_V1'\n",
    "    )\n",
    "\n",
    "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "best_model_path = \"models/deeplabv3_imagenet1k_best_model.pth\"\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Best model loaded successfully!\")\n",
    "print(f\"Best validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "print(f\"From epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5347dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 469/469 [07:11<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Average IoU: 0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_avg_iou = run_test(model=model,test_dataloader=syn_test_dataloader)\n",
    "print(f\"Test Average IoU: {test_avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2102e6",
   "metadata": {},
   "source": [
    "## DeeplabV3 Imagent1k 480x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8305cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 12500\n",
      "Train size: 7500 (60.0%)\n",
      "Validation size: 1250 (10.0%)\n",
      "Test size: 3750 (30.0%)\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 938\n",
      "Validation batches: 157\n",
      "Test batches: 469\n",
      "mps detected, using no_ssl_verification\n"
     ]
    }
   ],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 480)), # We augment from 466x256 to 480x256 in order to avoid the padding artifacts\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 480), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)\n",
    "\n",
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"Validation size: {val_size} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"Test size: {test_size} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(syn_train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(syn_val_dataloader)}\")\n",
    "print(f\"Test batches: {len(syn_test_dataloader)}\")\n",
    "\n",
    "if DEVICE.type == 'mps': \n",
    "    print(\"mps detected, using no_ssl_verification\")\n",
    "    with no_ssl_verification():\n",
    "        model = deeplabv3_resnet50(\n",
    "            weights='COCO_WITH_VOC_LABELS_V1', \n",
    "            weights_backbone='IMAGENET1K_V1'\n",
    "        )\n",
    "else:\n",
    "    model = deeplabv3_resnet50(\n",
    "        weights='COCO_WITH_VOC_LABELS_V1', \n",
    "        weights_backbone='IMAGENET1K_V1'\n",
    "    )\n",
    "\n",
    "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419c6940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from: models/deeplabv3_imagenet1k_480x256_best_model.pth\n",
      "Best model loaded successfully!\n",
      "Best validation IoU: 0.5857\n",
      "From epoch: 25\n"
     ]
    }
   ],
   "source": [
    "# Load the best model checkpoint\n",
    "best_model_path = \"models/deeplabv3_imagenet1k_480x256_best_model.pth\"\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Best model loaded successfully!\")\n",
    "print(f\"Best validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "print(f\"From epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac5ed0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 469/469 [07:21<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Average IoU: 0.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_avg_iou = run_test(model=model,test_dataloader=syn_test_dataloader)\n",
    "print(f\"Test Average IoU: {test_avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66657bcc",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb79a8",
   "metadata": {},
   "source": [
    "## Unet Imagenet1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e317c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 12500\n",
      "Train size: 7500 (60.0%)\n",
      "Validation size: 1250 (10.0%)\n",
      "Test size: 3750 (30.0%)\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 938\n",
      "Validation batches: 157\n",
      "Test batches: 469\n"
     ]
    }
   ],
   "source": [
    "path_images = \"syn_resized_images\"\n",
    "path_target = \"syn_resized_gt\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466)), # We maintain the og aspect ratio\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)\n",
    "\n",
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"Validation size: {val_size} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"Test size: {test_size} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(syn_train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(syn_val_dataloader)}\")\n",
    "print(f\"Test batches: {len(syn_test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ac4f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps detected, using no_ssl_verification\n",
      "Loading best model from: models/unet_imagenet1k_best_model.pth\n",
      "Best model loaded successfully!\n",
      "Best validation IoU: 0.5690\n",
      "From epoch: 25\n"
     ]
    }
   ],
   "source": [
    "class PaddedUnet(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', pretrained=True, in_channels=3, num_classes=19):\n",
    "        super(PaddedUnet, self).__init__()\n",
    "        # Initialize the original UNet model\n",
    "        self.unet = Unet(\n",
    "            backbone=backbone,\n",
    "            pretrained=pretrained,\n",
    "            in_channels=in_channels,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Save original dimensions for reference\n",
    "        orig_dim = x.shape[2:]\n",
    "        \n",
    "        # Encoder gives us a list of embeddings, one for each level\n",
    "        embeddings = self.unet.encoder(x)\n",
    "        embeddings.reverse()  # Reverse order to mach decoding \n",
    "        \n",
    "        # Manual decoding with padding fixes\n",
    "        x = embeddings[0]\n",
    "        \n",
    "        for i, block in enumerate(self.unet.decoder.blocks):\n",
    "            # Get skip connection if available\n",
    "            skip = embeddings[i+1] if i+1 < len(embeddings) else None\n",
    "            \n",
    "            # Handle upscaling if needed\n",
    "            if block.scale_factor > 1:\n",
    "                x = F.interpolate(x, scale_factor=block.scale_factor, mode='nearest')\n",
    "            \n",
    "            # Apply padding to match dimensions instead of resizing\n",
    "            # Needed since input shape is not divisible by 32\n",
    "            if skip is not None:\n",
    "                # Check if shapes need adjustment\n",
    "                if x.shape[2:] != skip.shape[2:]:\n",
    "                    # Calculate padding needed\n",
    "                    h_diff = x.shape[2] - skip.shape[2]\n",
    "                    w_diff = x.shape[3] - skip.shape[3]\n",
    "                    \n",
    "                    # Apply padding to match dimensions\n",
    "                    if h_diff > 0 or w_diff > 0:\n",
    "                        # Calculate padding values\n",
    "                        pad_h = (h_diff // 2, h_diff - h_diff // 2)\n",
    "                        pad_w = (w_diff // 2, w_diff - w_diff // 2)\n",
    "                        skip = F.pad(skip, [pad_w[0], pad_w[1], pad_h[0], pad_h[1]])\n",
    "                    elif h_diff < 0 or w_diff < 0:\n",
    "                        # Need to pad the x tensor instead\n",
    "                        h_diff = -h_diff\n",
    "                        w_diff = -w_diff\n",
    "                        pad_h = (h_diff // 2, h_diff - h_diff // 2)\n",
    "                        pad_w = (w_diff // 2, w_diff - w_diff // 2)\n",
    "                        x = F.pad(x, [pad_w[0], pad_w[1], pad_h[0], pad_h[1]])\n",
    "                \n",
    "                # Concatenate skip connection with current features\n",
    "                x = torch.cat([x, skip], dim=1)\n",
    "                \n",
    "            # Apply convolutions\n",
    "            x = block.conv1(x)\n",
    "            x = block.conv2(x)\n",
    "        \n",
    "        # Apply final convolution\n",
    "        x = self.unet.decoder.final_conv(x)\n",
    "        \n",
    "        # Ensure output matches input dimensions if needed\n",
    "        if x.shape[2:] != orig_dim:\n",
    "            x = F.interpolate(x, size=orig_dim, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return {'out': x}\n",
    "\n",
    "if DEVICE.type == 'mps':\n",
    "    print(\"mps detected, using no_ssl_verification\")\n",
    "    with no_ssl_verification():\n",
    "        model = PaddedUnet(\n",
    "            backbone='resnet50',\n",
    "            pretrained=True,\n",
    "            in_channels=3,\n",
    "            num_classes=NUM_CLASSES,\n",
    "        )\n",
    "else:\n",
    "    model = PaddedUnet(\n",
    "        backbone='resnet50',\n",
    "        pretrained=True,\n",
    "        in_channels=3,\n",
    "        num_classes=NUM_CLASSES,\n",
    "    )\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "best_model_path = \"models/unet_imagenet1k_best_model.pth\"\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Best model loaded successfully!\")\n",
    "print(f\"Best validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "print(f\"From epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ddf8b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 469/469 [02:56<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Average IoU: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_avg_iou = run_test(model=model,test_dataloader=syn_test_dataloader)\n",
    "print(f\"Test Average IoU: {test_avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d30f1",
   "metadata": {},
   "source": [
    "## Unet Imagenet1k 480x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93e5c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 12500\n",
      "Train size: 7500 (60.0%)\n",
      "Validation size: 1250 (10.0%)\n",
      "Test size: 3750 (30.0%)\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 938\n",
      "Validation batches: 157\n",
      "Test batches: 469\n"
     ]
    }
   ],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 480)), # We augment from 466x256 to 480x256 in order to avoid the padding artifacts\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 480), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)\n",
    "\n",
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"Validation size: {val_size} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"Test size: {test_size} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(syn_train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(syn_val_dataloader)}\")\n",
    "print(f\"Test batches: {len(syn_test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function for classic unet\n",
    "def run_test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_iou = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(test_dataloader, desc=\"Testing\")):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Collect metrics\n",
    "            test_total_iou += compute_iou(outputs.detach().cpu(), masks, NUM_CLASSES)\n",
    "            \n",
    "            # Explicit cleanup\n",
    "            del images, masks, outputs\n",
    "            \n",
    "            # Periodic memory clear\n",
    "            if (i + 1) % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    test_avg_iou = test_total_iou / len(test_dataloader)\n",
    "    return test_avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87b3664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps detected, using no_ssl_verification\n",
      "Loading best model from: models/unet_imagenet1k_480x256_best_model.pth\n",
      "Best model loaded successfully!\n",
      "Best validation IoU: 0.5983\n",
      "From epoch: 24\n"
     ]
    }
   ],
   "source": [
    "if DEVICE.type == 'mps':\n",
    "    print(\"mps detected, using no_ssl_verification\")\n",
    "    with no_ssl_verification():\n",
    "        model = Unet(\n",
    "            backbone='resnet50',\n",
    "            pretrained=True,\n",
    "            in_channels=3,\n",
    "            num_classes=NUM_CLASSES,\n",
    "        )\n",
    "else:\n",
    "    model = Unet(\n",
    "        backbone='resnet50',\n",
    "        pretrained=True,\n",
    "        in_channels=3,\n",
    "        num_classes=NUM_CLASSES,\n",
    "    )\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "best_model_path = \"models/unet_imagenet1k_480x256_best_model.pth\"\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Best model loaded successfully!\")\n",
    "print(f\"Best validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "print(f\"From epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d07b045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 469/469 [02:56<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Average IoU: 0.6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_avg_iou = run_test(model=model,test_dataloader=syn_test_dataloader)\n",
    "print(f\"Test Average IoU: {test_avg_iou:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
