{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d5ef39",
   "metadata": {},
   "source": [
    "# Domain Adaptation with Maximum Mean Discrepancy (MMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46150cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panal\\VSCode\\DLCV-Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from cityscapesscripts.helpers import labels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility is 42\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seeds(SEED)\n",
    "print(f\"Seeds set for reproducibility is {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecd025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6ac1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else \"mps\" if torch.mps.is_available() \n",
    "                      else \"cpu\"\n",
    "                    )\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02748e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, targets_dir, image_transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (string): Directory with all the images.\n",
    "            targets_dir (string): Directory with all the target masks.\n",
    "            image_transform (callable, optional): Optional transform to be applied on images.\n",
    "            target_transform (callable, optional): Optional transform to be applied on targets.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Get all image filenames\n",
    "        self.image_filenames = [f for f in os.listdir(images_dir) \n",
    "                               if f.lower().endswith(('.png'))]\n",
    "        self.image_filenames.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load target mask\n",
    "        target_name = img_name.replace('.png', '_trainId.png')\n",
    "        target_path = os.path.join(self.targets_dir, target_name)\n",
    "        target = Image.open(target_path)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "       # else:\n",
    "       #     # Default: convert to tensor\n",
    "       #     target = torch.from_numpy(target)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ecb33",
   "metadata": {},
   "source": [
    "### Loading the Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fed0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"syn_resized_images\"\n",
    "path_target = \"syn_resized_gt\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466)), # We maintain the og aspect ratio\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b133d44",
   "metadata": {},
   "source": [
    "### Splitting Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdec182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 5000\n",
      "Train size: 250 (5.0%)\n",
      "Validation size: 250 (5.0%)\n",
      "Test size: 4500 (90.0%)\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 63\n",
      "Validation batches: 63\n",
      "Test batches: 1125\n"
     ]
    }
   ],
   "source": [
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"Validation size: {val_size} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"Test size: {test_size} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 4 #8\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(syn_train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(syn_val_dataloader)}\")\n",
    "print(f\"Test batches: {len(syn_test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc3060",
   "metadata": {},
   "source": [
    "### Loading the Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226dce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Train dataset size: 2975\n",
      "Real Validation dataset size: 500\n",
      "Real Test dataset size: 1525\n"
     ]
    }
   ],
   "source": [
    "def cityscapes_mask_to_train_ids(mask):\n",
    "    mask_np = np.array(mask)\n",
    "    mask_np = np.where(mask_np <= 18, mask_np, 255).astype(np.uint8)\n",
    "    return torch.from_numpy(mask_np).long()\n",
    "\n",
    "real_target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: cityscapes_mask_to_train_ids(x))  # Convert Cityscapes mask to train IDs\n",
    "])\n",
    "\n",
    "real_train_dataset = Cityscapes(\n",
    "    root='cityscapes',\n",
    "    split='train',\n",
    "    mode='fine',\n",
    "    target_type='semantic',\n",
    "    transform=image_transform,\n",
    "    target_transform=real_target_transform\n",
    ")\n",
    "\n",
    "real_val_dataset = Cityscapes(\n",
    "    root='cityscapes',\n",
    "    split='val',\n",
    "    mode='fine',\n",
    "    target_type='semantic',\n",
    "    transform=image_transform,\n",
    "    target_transform=real_target_transform\n",
    ")\n",
    "\n",
    "real_test_dataset = Cityscapes(\n",
    "    root='cityscapes',\n",
    "    split='test',\n",
    "    mode='fine',\n",
    "    target_type='semantic',\n",
    "    transform=image_transform,\n",
    "    target_transform=real_target_transform\n",
    ")\n",
    "\n",
    "# Print dataloaders sizes\n",
    "print(f\"Real Train dataset size: {len(real_train_dataset)}\")\n",
    "print(f\"Real Validation dataset size: {len(real_val_dataset)}\")\n",
    "print(f\"Real Test dataset size: {len(real_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a35e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_dataloader = DataLoader(\n",
    "    real_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "real_val_dataloader = DataLoader(\n",
    "    real_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "real_test_dataloader = DataLoader(\n",
    "    real_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37ef0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=0.1, ignore_index=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: (N, C, H, W) - logits (non softmaxati)\n",
    "        targets: (N, H, W)   - ground truth con classi (0...C-1)\n",
    "        \"\"\"\n",
    "        num_classes = inputs.shape[1]\n",
    "        device = inputs.device  # Get device from input tensor\n",
    "        \n",
    "        # Softmax sulle predizioni\n",
    "        probs = F.softmax(inputs, dim=1)  # (N, C, H, W)\n",
    "        \n",
    "        # Handle ignore_index by creating a mask and filtering out ignored pixels\n",
    "        if self.ignore_index is not None:\n",
    "            # Create mask for valid pixels\n",
    "            valid_mask = (targets != self.ignore_index)  # (N, H, W)\n",
    "            \n",
    "            # Only process valid pixels\n",
    "            valid_targets = targets[valid_mask]  # (N_valid,)\n",
    "            \n",
    "            # Reshape probs to match and filter valid pixels\n",
    "            probs_reshaped = probs.permute(0, 2, 3, 1)  # (N, H, W, C)\n",
    "            valid_probs = probs_reshaped[valid_mask]  # (N_valid, C)\n",
    "            \n",
    "        else:\n",
    "            # No ignore_index, process all pixels\n",
    "            valid_targets = targets.view(-1)  # (N*H*W,)\n",
    "            valid_probs = probs.permute(0, 2, 3, 1).contiguous().view(-1, num_classes)  # (N*H*W, C)\n",
    "        \n",
    "        # One-hot encoding of valid targets only\n",
    "        if len(valid_targets) > 0:\n",
    "            targets_one_hot = F.one_hot(valid_targets, num_classes=num_classes).float()  # (N_valid, C)\n",
    "        else:\n",
    "            # If no valid pixels, create a zero loss that maintains gradients\n",
    "            # Use a small operation on the input to maintain gradient flow\n",
    "            zero_loss = (inputs * 0.0).sum()  # This maintains gradients from inputs\n",
    "            return zero_loss\n",
    "        \n",
    "        # Calcolo Dice per ogni classe usando solo pixel validi\n",
    "        intersection = (valid_probs * targets_one_hot).sum(dim=0)  # (C,)\n",
    "        union = valid_probs.sum(dim=0) + targets_one_hot.sum(dim=0)  # (C,)\n",
    "        \n",
    "        \n",
    "        smooth_tensor = torch.tensor(self.smooth, device=device, dtype=intersection.dtype)\n",
    "        dice = (2.0 * intersection + smooth_tensor) / (union + smooth_tensor)\n",
    "        \n",
    "        # Media sulle classi\n",
    "        loss = 1.0 - dice.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9329fb",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy Loss (MMD) \n",
    "$$\n",
    "    MMD(X, Y) = \\frac{1}{|X|^2} \\sum_{i,j} k(x_i, x_j) - \\frac{2}{|X||Y|} \\sum_{i,j} k(x_i, y_j) + \\frac{1}{|Y|^2} \\sum_{i,j} k(y_i, y_j)\n",
    "$$\n",
    "where:\n",
    "- $k$ is a kernel function (e.g., Gaussian).\n",
    "- $X$ is the source domain (MNIST) and $Y$ is the target domain (SVHN).\n",
    "- $x_i$ and $y_j$ are samples from the respective domains.\n",
    "- $|X|$ and $|Y|$ are the number of samples in each domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b879bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MMD loss between source and target feature batches\n",
    "def rbf_kernel(a, b, sigma):\n",
    "    a = a.unsqueeze(1) \n",
    "    b = b.unsqueeze(0) \n",
    "    dist = (a - b).pow(2).sum(2) \n",
    "    return torch.exp(-dist / (2 * sigma ** 2))\n",
    "\n",
    "def MMD_loss(x, y, sigma=1.0):\n",
    "\n",
    "    K_xx = rbf_kernel(x, x, sigma)\n",
    "    K_yy = rbf_kernel(y, y, sigma)\n",
    "    K_xy = rbf_kernel(x, y, sigma)\n",
    "    mmd = K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_loss_ignore_index(x, y, sigma=1.0, ignore_index=255):\n",
    "\n",
    "    # Flatten if needed (e.g., for segmentation outputs)\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    y_flat = y.view(y.size(0), -1)\n",
    "\n",
    "    # Create mask for ignore_index\n",
    "    x_mask = ~(x_flat == ignore_index).any(dim=1)\n",
    "    y_mask = ~(y_flat == ignore_index).any(dim=1)\n",
    "\n",
    "    x_valid = x_flat[x_mask]\n",
    "    y_valid = y_flat[y_mask]\n",
    "\n",
    "    # If no valid samples, return zero loss with gradient\n",
    "    if x_valid.size(0) == 0 or y_valid.size(0) == 0:\n",
    "        return (x.sum() * 0.0) + (y.sum() * 0.0) # This maintains gradients from x and y\n",
    "\n",
    "    K_xx = rbf_kernel(x_valid, x_valid, sigma)\n",
    "    K_yy = rbf_kernel(y_valid, y_valid, sigma)\n",
    "    K_xy = rbf_kernel(x_valid, y_valid, sigma)\n",
    "    mmd = K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b66662",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 19\n",
    "LR = 1e-4\n",
    "\n",
    "CE_loss = nn.CrossEntropyLoss(ignore_index=255)  # 255 = unlabeled\n",
    "Dice_loss = DiceLoss(smooth=0.1, ignore_index=255)  \n",
    "\n",
    "ce_importance = 0.7\n",
    "mmd_weight = 0.1\n",
    "\n",
    "def criterion(outputs, targets):\n",
    "    ce_loss = CE_loss(outputs, targets)\n",
    "    dice_loss = Dice_loss(outputs, targets)\n",
    "\n",
    "    cls_loss = ce_importance * ce_loss + (1 - ce_importance) * dice_loss\n",
    "    return cls_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e36576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "# Instantiate the model architecture\n",
    "model = deeplabv3_resnet50(num_classes=NUM_CLASSES)\n",
    "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load the checkpoint and filter out aux_classifier keys\n",
    "checkpoint = torch.load(\"models/deeplabv3_resnet50_best_model.pth\", map_location=DEVICE)\n",
    "state_dict = checkpoint[\"model_state_dict\"]\n",
    "filtered_state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"aux_classifier.\")}\n",
    "model.load_state_dict(filtered_state_dict, strict=False)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83b9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds, labels, num_classes, ignore_index=255):\n",
    "    \n",
    "    preds = torch.argmax(preds, dim=1).detach().cpu()  # [B, H, W]\n",
    "    \n",
    "    labels = labels.detach().cpu() \n",
    "    \n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (labels == cls)\n",
    "        \n",
    "        # Escludi pixel ignorati\n",
    "        mask = (labels != ignore_index)\n",
    "        pred_inds = pred_inds & mask\n",
    "        target_inds = target_inds & mask\n",
    "\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        \n",
    "        if union == 0:\n",
    "            continue  # salta classe non presente\n",
    "        ious.append(intersection / union)\n",
    "    \n",
    "    if len(ious) == 0:\n",
    "        return float('nan')  # o 0.0 se preferisci\n",
    "    return sum(ious) / len(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5bea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Clear memory and cache for all device types\"\"\"\n",
    "    # Delete all local variables in the caller's frame\n",
    "    for obj in list(locals().values()):\n",
    "        del obj\n",
    "        \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if DEVICE.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    # Second GC run to make sure everything is cleaned up\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c10edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_epoch(\n",
    "            model, optimizer, criterion, \n",
    "            syn_train_dataloader, syn_val_dataloader,\n",
    "            real_train_dataloader, real_val_dataloader\n",
    "    ):\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_total_loss = 0\n",
    "    train_cls_loss = 0\n",
    "    train_mmd_loss = 0\n",
    "    train_iou_source = 0\n",
    "    train_iou_target = 0\n",
    "\n",
    "    syn_train_iter = iter(syn_train_dataloader)\n",
    "    real_train_iter = iter(real_train_dataloader)\n",
    "    \n",
    "    steps = min(len(syn_train_iter), len(real_train_iter))\n",
    "\n",
    "    for i in tqdm(range(steps),desc=\"Training\"):\n",
    "        source_data, source_labels = next(syn_train_iter)\n",
    "        target_data, target_labels = next(real_train_iter)\n",
    "\n",
    "        source_data, source_labels = source_data.to(DEVICE), source_labels.to(DEVICE)\n",
    "        target_data = target_data.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        source_backbone_out = model.backbone(source_data)\n",
    "        source_embeddings = source_backbone_out['out']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_backbone_out = model.backbone(target_data)\n",
    "            target_embeddings = target_backbone_out['out']\n",
    "\n",
    "        target_embeddings.requires_grad = True\n",
    "\n",
    "        source_output = model(source_data)['out']\n",
    "        target_output = model(target_data)['out']\n",
    "\n",
    "        cls_loss = criterion(source_output, source_labels)\n",
    "        mmd_loss = MMD_loss_ignore_index(source_embeddings, target_embeddings)\n",
    "\n",
    "        loss = cls_loss + mmd_weight * mmd_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect metrics (detach to prevent graph retention)\n",
    "        train_total_loss += loss.detach().cpu().item()\n",
    "\n",
    "        train_cls_loss += cls_loss.detach().cpu().item()\n",
    "        train_mmd_loss += mmd_loss.detach().cpu().item()\n",
    "\n",
    "        iou_target = compute_iou(target_output.detach().cpu(), target_labels, NUM_CLASSES)\n",
    "        iou_source = compute_iou(source_output.detach().cpu(), source_labels, NUM_CLASSES)\n",
    "        \n",
    "        train_iou_source += iou_source\n",
    "        train_iou_target += iou_target\n",
    "        \n",
    "        # Explicit cleanup of tensors to prevent memory leaks\n",
    "        del source_data, source_labels, target_data, target_labels\n",
    "        del source_embeddings, target_embeddings, source_output, target_output\n",
    "        del loss, cls_loss, mmd_loss\n",
    "        \n",
    "        # Periodically clear memory (every 5 batches)\n",
    "        if (i + 1) % 5 == 0:\n",
    "            clear_memory()  \n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    source_train_avg_loss = train_total_loss / steps\n",
    "    source_train_avg_iou = train_iou_source / steps\n",
    "    target_train_avg_iou = train_iou_target / steps\n",
    "    \n",
    "    # Validation \n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    val_iou_source = 0\n",
    "    val_iou_target = 0\n",
    "\n",
    "    val_steps = min(len(syn_val_dataloader), len(real_val_dataloader))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in tqdm(range(val_steps), desc=\"Validation\"):\n",
    "            source_data, source_labels = next(iter(syn_val_dataloader))\n",
    "            target_data, target_labels = next(iter(real_val_dataloader))\n",
    "            source_data, source_labels = source_data.to(DEVICE), source_labels.to(DEVICE)\n",
    "            target_data, target_labels = target_data.to(DEVICE), target_labels.to(DEVICE)\n",
    "\n",
    "            outputs_source = model(source_data)['out']\n",
    "            outputs_target = model(target_data)['out']\n",
    "\n",
    "            loss_real = criterion(outputs_source, source_labels)\n",
    "            loss_target = criterion(outputs_target, target_labels)\n",
    "\n",
    "            val_total_loss += loss_real.detach().cpu().item() \n",
    "            val_iou_source += compute_iou(outputs_source.detach().cpu(), source_labels, NUM_CLASSES)\n",
    "            val_iou_target += compute_iou(outputs_target.detach().cpu(), target_labels, NUM_CLASSES)\n",
    "\n",
    "            # Explicit cleanup\n",
    "            del source_data, source_labels, target_data, target_labels\n",
    "            del outputs_source, outputs_target, loss_real, loss_target\n",
    "            \n",
    "            # Periodic memory clear\n",
    "            if (i + 1) % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # Average losses and IOUs\n",
    "    source_val_avg_loss = val_total_loss / val_steps\n",
    "    source_val_avg_iou = val_iou_source / val_steps\n",
    "    target_val_avg_iou = val_iou_target / val_steps\n",
    "    \n",
    "    return source_train_avg_loss, source_train_avg_iou, target_train_avg_iou, \\\n",
    "            source_val_avg_loss, source_val_avg_iou, target_val_avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ba2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adaptation(\n",
    "        start_epoch, end_epoch,\n",
    "        model, optimizer, criterion, \n",
    "        syn_train_dataloader, syn_val_dataloader, \n",
    "        real_train_dataloader, real_val_dataloader\n",
    "    ):\n",
    "\n",
    "    # Create models directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    st_losses = []  # Source Training losses\n",
    "    st_ious = []  # Source Training IoUs\n",
    "    tt_losses = []  # Target Training losses\n",
    "    sv_losses = []  # Source Validation losses\n",
    "    sv_ious = []  # Source Validation IoUs\n",
    "    tv_ious = []  # Target Validation IoUs\n",
    "\n",
    "    # Track best validation IoU for saving best model\n",
    "    best_source_val_iou = 0.0\n",
    "    best_target_val_iou = 0.0\n",
    "    start = time.time()\n",
    "\n",
    "    set_seeds(SEED)\n",
    "    \n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        print(f\"Epoch {epoch+1}/{end_epoch}\")\n",
    "        \n",
    "        # Train and validate in one go\n",
    "        source_train_avg_loss, source_train_avg_iou, target_train_avg_iou, \\\n",
    "            source_val_avg_loss, source_val_avg_iou, target_val_avg_iou = \\\n",
    "        train_and_validate_epoch(\n",
    "            model, optimizer, criterion, \n",
    "            syn_train_dataloader, syn_val_dataloader,\n",
    "            real_train_dataloader, real_val_dataloader\n",
    "        )\n",
    "        \n",
    "        # Store metrics\n",
    "        st_losses.append(source_train_avg_loss)\n",
    "        st_ious.append(source_train_avg_iou)\n",
    "        tt_losses.append(target_train_avg_iou)\n",
    "        sv_losses.append(source_val_avg_loss)\n",
    "        sv_ious.append(source_val_avg_iou)\n",
    "        tv_ious.append(target_val_avg_iou)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Source Train Loss: {source_train_avg_loss:.4f} | Source Train IoU: {source_train_avg_iou:.4f}\")\n",
    "        print(f\"Target Train IoU: {target_train_avg_iou:.4f}\")\n",
    "        print(f\"Source Val Loss: {source_val_avg_loss:.4f} | Source Val IoU: {source_val_avg_iou:.4f}\")\n",
    "        print(f\"Target Val IoU: {target_val_avg_iou:.4f}\")\n",
    "        \n",
    "        # Save checkpoint after each epoch\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"source_train_avg_loss\": source_train_avg_loss,\n",
    "            \"source_train_avg_iou\": source_train_avg_iou,\n",
    "            \"target_train_avg_iou\": target_train_avg_iou,\n",
    "            \"source_val_avg_loss\": source_val_avg_loss,\n",
    "            \"source_val_avg_iou\": source_val_avg_iou,\n",
    "            \"target_val_avg_iou\": target_val_avg_iou,\n",
    "            \"st_losses\": st_losses,\n",
    "            \"st_ious\": st_ious,\n",
    "            \"tt_losses\": tt_losses,\n",
    "            \"sv_losses\": sv_losses,\n",
    "            \"sv_ious\": sv_ious,\n",
    "            \"tv_ious\": tv_ious,\n",
    "            \"num_classes\": NUM_CLASSES,\n",
    "            \"learning_rate\": LR,\n",
    "        }\n",
    "        \n",
    "        name = \"DA_deeplabv3_resnet50\"\n",
    "\n",
    "        # Save best model based on validation IoU\n",
    "        source_val_iou = source_val_avg_iou\n",
    "        target_val_iou = target_val_avg_iou\n",
    "\n",
    "        if source_val_iou > best_source_val_iou:\n",
    "            best_val_iou = source_val_iou\n",
    "            best_model_path = f\"models/{name}_best_unsupervised_model.pth\"\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"New best model saved: {best_model_path} (Source Val IoU: {source_val_iou:.4f})\")\n",
    "\n",
    "        if target_val_iou > best_target_val_iou:\n",
    "            best_val_iou = target_val_iou\n",
    "            best_model_path = f\"models/{name}_best_supervised_model.pth\"\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"New best model saved: {best_model_path} (Target Val IoU: {target_val_iou:.4f})\")\n",
    "        \n",
    "        checkpoint_path = f\"models/{name}_epoch_{epoch+1}.pth\"\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "        # Delete old checkpoints if they exist\n",
    "        checkpoint_delete = f\"models/{name}_epoch_{epoch}.pth\"\n",
    "        if os.path.exists(checkpoint_delete):\n",
    "            os.remove(checkpoint_delete)\n",
    "            print(f\"Deleted old checkpoint: {checkpoint_delete}\")\n",
    "        \n",
    "        del checkpoint\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(f\"\\nTraining completed in {end - start:.2f} seconds, with {end_epoch} epochs.\")\n",
    "    print(f\"Best validation IoU: {best_val_iou:.4f}\")\n",
    "    print(f\"Final model saved as: models/{name}_epoch_{end_epoch}.pth\")\n",
    "    print(f\"Best model saved as: models/{name}_best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab54204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6/6 [02:02<00:00, 20.41s/it]\n",
      "Validation: 100%|██████████| 6/6 [00:13<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train Loss: 0.2519 | Source Train IoU: 0.6054\n",
      "Target Train IoU: 0.0093\n",
      "Source Val Loss: 0.3088 | Source Val IoU: 0.5207\n",
      "Target Val IoU: 0.0119\n",
      "New best model saved: models/DA_deeplabv3_resnet50_best_model.pth (Val IoU: 0.5207)\n",
      "Checkpoint saved: models/DA_deeplabv3_resnet50_epoch_1.pth\n",
      "--------------------------------------------------\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6/6 [02:25<00:00, 24.24s/it]\n",
      "Validation: 100%|██████████| 6/6 [00:13<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train Loss: 0.2408 | Source Train IoU: 0.6388\n",
      "Target Train IoU: 0.0117\n",
      "Source Val Loss: 0.3460 | Source Val IoU: 0.5049\n",
      "Target Val IoU: 0.0130\n",
      "Checkpoint saved: models/DA_deeplabv3_resnet50_epoch_2.pth\n",
      "Deleted old checkpoint: models/DA_deeplabv3_resnet50_epoch_1.pth\n",
      "--------------------------------------------------\n",
      "\n",
      "Training completed in 298.05 seconds, with 2 epochs.\n",
      "Best validation IoU: 0.5207\n",
      "Final model saved as: models/DA_deeplabv3_resnet50_epoch_2.pth\n",
      "Best model saved as: models/DA_deeplabv3_resnet50_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "domain_adaptation(\n",
    "    start_epoch=0, \n",
    "    end_epoch=2,\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion, \n",
    "    syn_train_dataloader=syn_train_dataloader, \n",
    "    syn_val_dataloader=syn_val_dataloader, \n",
    "    real_train_dataloader=real_train_dataloader, \n",
    "    real_val_dataloader=real_val_dataloader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
