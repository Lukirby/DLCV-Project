{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d5ef39",
   "metadata": {},
   "source": [
    "# Domain Adaptation with Maximum Mean Discrepancy (MMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46150cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from cityscapesscripts.helpers import labels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility is 42\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seeds(SEED)\n",
    "print(f\"Seeds set for reproducibility is {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6ac1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else \"mps\" if torch.mps.is_available() \n",
    "                      else \"cpu\"\n",
    "                    )\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02748e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, targets_dir, image_transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (string): Directory with all the images.\n",
    "            targets_dir (string): Directory with all the target masks.\n",
    "            image_transform (callable, optional): Optional transform to be applied on images.\n",
    "            target_transform (callable, optional): Optional transform to be applied on targets.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Get all image filenames\n",
    "        self.image_filenames = [f for f in os.listdir(images_dir) \n",
    "                               if f.lower().endswith(('.png'))]\n",
    "        self.image_filenames.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load target mask\n",
    "        target_name = img_name.replace('.png', '_trainId.png')\n",
    "        target_path = os.path.join(self.targets_dir, target_name)\n",
    "        target = Image.open(target_path)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "       # else:\n",
    "       #     # Default: convert to tensor\n",
    "       #     target = torch.from_numpy(target)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"syn_resized_images\"\n",
    "path_target = \"syn_resized_gt\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466)), # We maintain the og aspect ratio\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdec182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"Validation size: {val_size} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"Test size: {test_size} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(syn_train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(syn_val_dataloader)}\")\n",
    "print(f\"Test batches: {len(syn_test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ef0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=0.1, ignore_index=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: (N, C, H, W) - logits (non softmaxati)\n",
    "        targets: (N, H, W)   - ground truth con classi (0...C-1)\n",
    "        \"\"\"\n",
    "        num_classes = inputs.shape[1]\n",
    "        device = inputs.device  # Get device from input tensor\n",
    "        \n",
    "        # Softmax sulle predizioni\n",
    "        probs = F.softmax(inputs, dim=1)  # (N, C, H, W)\n",
    "        \n",
    "        # Handle ignore_index by creating a mask and filtering out ignored pixels\n",
    "        if self.ignore_index is not None:\n",
    "            # Create mask for valid pixels\n",
    "            valid_mask = (targets != self.ignore_index)  # (N, H, W)\n",
    "            \n",
    "            # Only process valid pixels\n",
    "            valid_targets = targets[valid_mask]  # (N_valid,)\n",
    "            \n",
    "            # Reshape probs to match and filter valid pixels\n",
    "            probs_reshaped = probs.permute(0, 2, 3, 1)  # (N, H, W, C)\n",
    "            valid_probs = probs_reshaped[valid_mask]  # (N_valid, C)\n",
    "            \n",
    "        else:\n",
    "            # No ignore_index, process all pixels\n",
    "            valid_targets = targets.view(-1)  # (N*H*W,)\n",
    "            valid_probs = probs.permute(0, 2, 3, 1).contiguous().view(-1, num_classes)  # (N*H*W, C)\n",
    "        \n",
    "        # One-hot encoding of valid targets only\n",
    "        if len(valid_targets) > 0:\n",
    "            targets_one_hot = F.one_hot(valid_targets, num_classes=num_classes).float()  # (N_valid, C)\n",
    "        else:\n",
    "            # If no valid pixels, create a zero loss that maintains gradients\n",
    "            # Use a small operation on the input to maintain gradient flow\n",
    "            zero_loss = (inputs * 0.0).sum()  # This maintains gradients from inputs\n",
    "            return zero_loss\n",
    "        \n",
    "        # Calcolo Dice per ogni classe usando solo pixel validi\n",
    "        intersection = (valid_probs * targets_one_hot).sum(dim=0)  # (C,)\n",
    "        union = valid_probs.sum(dim=0) + targets_one_hot.sum(dim=0)  # (C,)\n",
    "        \n",
    "        \n",
    "        smooth_tensor = torch.tensor(self.smooth, device=device, dtype=intersection.dtype)\n",
    "        dice = (2.0 * intersection + smooth_tensor) / (union + smooth_tensor)\n",
    "        \n",
    "        # Media sulle classi\n",
    "        loss = 1.0 - dice.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9329fb",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy Loss (MMD) \n",
    "$$\n",
    "    MMD(X, Y) = \\frac{1}{|X|^2} \\sum_{i,j} k(x_i, x_j) - \\frac{2}{|X||Y|} \\sum_{i,j} k(x_i, y_j) + \\frac{1}{|Y|^2} \\sum_{i,j} k(y_i, y_j)\n",
    "$$\n",
    "where:\n",
    "- $k$ is a kernel function (e.g., Gaussian).\n",
    "- $X$ is the source domain (MNIST) and $Y$ is the target domain (SVHN).\n",
    "- $x_i$ and $y_j$ are samples from the respective domains.\n",
    "- $|X|$ and $|Y|$ are the number of samples in each domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b879bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MMD loss between source and target feature batches\n",
    "def rbf_kernel(a, b, sigma):\n",
    "    a = a.unsqueeze(1) \n",
    "    b = b.unsqueeze(0) \n",
    "    dist = (a - b).pow(2).sum(2) \n",
    "    return torch.exp(-dist / (2 * sigma ** 2))\n",
    "\n",
    "def MMD_loss(x, y, sigma=1.0):\n",
    "\n",
    "    K_xx = rbf_kernel(x, x, sigma)\n",
    "    K_yy = rbf_kernel(y, y, sigma)\n",
    "    K_xy = rbf_kernel(x, y, sigma)\n",
    "    mmd = K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_loss_ignore_index(x, y, sigma=1.0, ignore_index=255):\n",
    "\n",
    "    # Flatten if needed (e.g., for segmentation outputs)\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    y_flat = y.view(y.size(0), -1)\n",
    "\n",
    "    # Create mask for ignore_index\n",
    "    x_mask = ~(x_flat == ignore_index).any(dim=1)\n",
    "    y_mask = ~(y_flat == ignore_index).any(dim=1)\n",
    "\n",
    "    x_valid = x_flat[x_mask]\n",
    "    y_valid = y_flat[y_mask]\n",
    "\n",
    "    # If no valid samples, return zero loss with gradient\n",
    "    if x_valid.size(0) == 0 or y_valid.size(0) == 0:\n",
    "        return (x.sum() * 0.0) + (y.sum() * 0.0) # This maintains gradients from x and y\n",
    "\n",
    "    K_xx = rbf_kernel(x_valid, x_valid, sigma)\n",
    "    K_yy = rbf_kernel(y_valid, y_valid, sigma)\n",
    "    K_xy = rbf_kernel(x_valid, y_valid, sigma)\n",
    "    mmd = K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b66662",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 19\n",
    "LR = 1e-4\n",
    "\n",
    "CE_loss = nn.CrossEntropyLoss(ignore_index=255)  # 255 = unlabeled\n",
    "Dice_loss = DiceLoss(smooth=0.1, ignore_index=255)  \n",
    "\n",
    "ce_importance = 0.7\n",
    "mmd_weight = 0.1\n",
    "\n",
    "def criterion(outputs, targets):\n",
    "    ce_loss = CE_loss(outputs, targets)\n",
    "    dice_loss = Dice_loss(outputs, targets)\n",
    "\n",
    "    cls_loss = ce_importance * ce_loss + (1 - ce_importance) * dice_loss\n",
    "    return cls_loss #+ mmd_weight * MMD_loss(outputs, targets.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e36576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "model = \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds, labels, num_classes, ignore_index=255):\n",
    "    \n",
    "    preds = torch.argmax(preds, dim=1).detach().cpu()  # [B, H, W]\n",
    "    \n",
    "    labels = labels.detach().cpu() \n",
    "    \n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (labels == cls)\n",
    "        \n",
    "        # Escludi pixel ignorati\n",
    "        mask = (labels != ignore_index)\n",
    "        pred_inds = pred_inds & mask\n",
    "        target_inds = target_inds & mask\n",
    "\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        \n",
    "        if union == 0:\n",
    "            continue  # salta classe non presente\n",
    "        ious.append(intersection / union)\n",
    "    \n",
    "    if len(ious) == 0:\n",
    "        return float('nan')  # o 0.0 se preferisci\n",
    "    return sum(ious) / len(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5bea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Clear memory and cache for all device types\"\"\"\n",
    "    # Delete all local variables in the caller's frame\n",
    "    for obj in list(locals().values()):\n",
    "        del obj\n",
    "        \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if DEVICE.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    # Second GC run to make sure everything is cleaned up\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43273884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_epoch(\n",
    "            model, optimizer, criterion, \n",
    "            syn_train_dataloader, syn_val_dataloader,\n",
    "            real_train_dataloader, real_val_dataloader\n",
    "    ):\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_total_loss = 0\n",
    "    train_cls_loss = 0\n",
    "    train_mmd_loss = 0\n",
    "    train_iou_source = 0\n",
    "    train_iou_target = 0\n",
    "\n",
    "    syn_train_iter = iter(syn_train_dataloader)\n",
    "    real_train_iter = iter(real_train_dataloader)\n",
    "    \n",
    "    steps = min(len(syn_train_iter), len(real_train_iter))\n",
    "\n",
    "    for _ in tqdm(range(steps),desc=\"Training\"):\n",
    "        source_data, source_labels = next(syn_train_iter)\n",
    "        target_data, target_labels = next(real_train_iter)\n",
    "\n",
    "        source_data, source_labels = source_data.to(DEVICE), source_labels.to(DEVICE)\n",
    "        target_data = target_data.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        source_embeddings = model.backbone(source_data)\n",
    "        target_embeddings = model.backbone(target_data)\n",
    "\n",
    "        source_output = model.classifier(source_embeddings)['out']\n",
    "        target_output = model.classifier(target_embeddings)['out']\n",
    "\n",
    "        cls_loss = criterion(source_output, source_labels)\n",
    "        mmd_loss = MMD_loss_ignore_index(source_embeddings, target_embeddings)\n",
    "\n",
    "        loss = cls_loss + mmd_weight * mmd_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect metrics (detach to prevent graph retention)\n",
    "        train_total_loss += loss.detach().cpu().item()\n",
    "        train_cls_loss += cls_loss.detach().cpu().item()\n",
    "        train_mmd_loss += mmd_loss.detach().cpu().item()\n",
    "        iou_target = compute_iou(target_output.detach().cpu(), target_labels, NUM_CLASSES)\n",
    "        iou_source = compute_iou(source_output.detach().cpu(), source_labels, NUM_CLASSES)\n",
    "        train_iou_source += iou_source\n",
    "        train_iou_target += iou_target\n",
    "        \n",
    "        # Explicit cleanup of tensors to prevent memory leaks\n",
    "        del source_data, source_labels, target_data, target_labels\n",
    "        del source_embeddings, target_embeddings, source_output, target_output\n",
    "        del loss, cls_loss, mmd_loss\n",
    "        \n",
    "        # Periodically clear memory (every 5 batches)\n",
    "        if (i + 1) % 5 == 0:\n",
    "            clear_memory()  \n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    train_avg_loss = train_total_loss / len(real_train_dataloader)\n",
    "    train_avg_iou = train_iou_source / len(real_train_dataloader)\n",
    "    \n",
    "    # Validation \n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    val_total_iou = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(syn_val_dataloader, desc=\"Validation\")):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Collect metrics\n",
    "            val_total_loss += loss.detach().cpu().item()\n",
    "            val_total_iou += compute_iou(outputs.detach().cpu(), masks, NUM_CLASSES)\n",
    "            \n",
    "            # Explicit cleanup\n",
    "            del images, masks, outputs, loss\n",
    "            \n",
    "            # Periodic memory clear\n",
    "            if (i + 1) % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    val_avg_loss = val_total_loss / len(val_dataloader)\n",
    "    val_avg_iou = val_total_iou / len(val_dataloader)\n",
    "    \n",
    "    return train_avg_loss, train_avg_iou, val_avg_loss, val_avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model_dann.train()\n",
    "    total_cls_loss, total_mmd_loss = 0, 0\n",
    "\n",
    "    mnist_iter = iter(train_loader_mnist)\n",
    "    svhn_iter = iter(test_loader_svhn)  # unlabeled target domain\n",
    "\n",
    "    steps = min(len(mnist_iter), len(svhn_iter))\n",
    "\n",
    "    for _ in range(steps):\n",
    "        source_data, source_labels = next(mnist_iter)\n",
    "        target_data, _ = next(svhn_iter)\n",
    "\n",
    "        source_data, source_labels = source_data.to(device), source_labels.to(device)\n",
    "        target_data = target_data.to(device)\n",
    "\n",
    "        optimizer_dann.zero_grad()\n",
    "\n",
    "        #Forward pass\n",
    "        source_features = model_dann.features(source_data)\n",
    "        target_features = model_dann.features(target_data)\n",
    "\n",
    "        source_output = model_dann.classifier(source_features)\n",
    "        \n",
    "        #compute Losses\n",
    "        \n",
    "        cls_loss = criterion(source_output, source_labels)\n",
    "        mmd_loss = compute_mmd(source_features, target_features)\n",
    "\n",
    "        total_loss = cls_loss + lambda_mmd * mmd_loss\n",
    "        total_loss.backward()\n",
    "        optimizer_dann.step()\n",
    "\n",
    "        total_cls_loss += cls_loss.item()\n",
    "        total_mmd_loss += mmd_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Cls Loss: {total_cls_loss/steps:.4f} | MMD Loss: {total_mmd_loss/steps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ba2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adaptation(\n",
    "        start_epoch, end_epoch,\n",
    "        model, optimizer, criterion, \n",
    "        syn_train_dataloader, syn_val_dataloader, \n",
    "        real_train_dataloader, real_val_dataloader\n",
    "    ):\n",
    "\n",
    "    # Create models directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses = []\n",
    "    train_ious = []\n",
    "    val_losses = []\n",
    "    val_ious = []\n",
    "\n",
    "    # Track best validation IoU for saving best model\n",
    "    best_val_iou = 0.0\n",
    "    start = time.time()\n",
    "\n",
    "    set_seeds(SEED)\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        print(f\"Epoch {epoch+1}/{end_epoch}\")\n",
    "        \n",
    "        # Train and validate in one go\n",
    "        train_loss, train_iou, val_loss, val_iou = train_and_validate_epoch(\n",
    "            model, optimizer, criterion, \n",
    "            syn_train_dataloader, syn_val_dataloader,\n",
    "            real_train_dataloader, real_val_dataloader\n",
    "        )\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)  \n",
    "        train_ious.append(train_iou)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ious.append(val_iou)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train IoU: {train_iou:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        # Save checkpoint after each epoch\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_iou\": train_iou,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_iou\": val_iou,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"train_ious\": train_ious,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"val_ious\": val_ious,\n",
    "            \"num_classes\": NUM_CLASSES,\n",
    "            \"learning_rate\": LR,\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # Save best model based on validation IoU\n",
    "        if val_iou > best_val_iou:\n",
    "            best_val_iou = val_iou\n",
    "            best_model_path = \"models/deeplabv3_resnet50_best_model.pth\"\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"New best model saved: {best_model_path} (Val IoU: {val_iou:.4f})\")\n",
    "        \n",
    "        checkpoint_path = f\"models/deeplabv3_resnet50_epoch_{epoch+1}.pth\"\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "        # Delete old checkpoints if they exist\n",
    "        checkpoint_delete = f\"models/deeplabv3_resnet50_epoch_{epoch}.pth\"\n",
    "        if os.path.exists(checkpoint_delete):\n",
    "            os.remove(checkpoint_delete)\n",
    "            print(f\"Deleted old checkpoint: {checkpoint_delete}\")\n",
    "        \n",
    "        del checkpoint\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(f\"\\nTraining completed in {end - start:.2f} seconds, with {end_epoch} epochs.\")\n",
    "    print(f\"Best validation IoU: {best_val_iou:.4f}\")\n",
    "    print(f\"Final model saved as: models/deeplabv3_resnet50_epoch_{end_epoch}.pth\")\n",
    "    print(f\"Best model saved as: models/deeplabv3_resnet50_best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
