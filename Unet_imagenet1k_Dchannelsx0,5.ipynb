{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1f85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install pretrained-backbones-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d507051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from cityscapesscripts.helpers import labels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import backbones_unet\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from backbones_unet.model.unet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db78fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility is 42\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seeds(SEED)\n",
    "print(f\"Seeds set for reproducibility is {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d727efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else \"mps\" if torch.mps.is_available() \n",
    "                      else \"cpu\"\n",
    "                    )\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fedc9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Colors:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1400 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Actual Colors:\")\n",
    "\n",
    "# Calculate grid dimensions (3 colors per row)\n",
    "cols = 3\n",
    "\n",
    "labels = [label for label in labels.labels if label.trainId != 255 and label.trainId != -1]\n",
    "rows = (len(labels) + cols - 1) // cols  # Ceiling division\n",
    "\n",
    "# Create a figure and axes to display the colors in a grid\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, rows * 2))\n",
    "\n",
    "# Flatten axes array for easier indexing\n",
    "if rows == 1:\n",
    "    axes = [axes] if cols == 1 else axes\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for i, label in enumerate(labels): \n",
    "    color = np.array(label.color) / 255.0  # Normalize RGB values to [0, 1]\n",
    "    axes[i].imshow([[color]])  # Display the color as a small image\n",
    "    # Add color name and RGB values to the title\n",
    "    axes[i].set_title(f\"{label.name}\\n{label.color}\", fontsize=8)\n",
    "    axes[i].axis('off')  # Hide the axes\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(len(labels), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61293454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, targets_dir, image_transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (string): Directory with all the images.\n",
    "            targets_dir (string): Directory with all the target masks.\n",
    "            image_transform (callable, optional): Optional transform to be applied on images.\n",
    "            target_transform (callable, optional): Optional transform to be applied on targets.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Get all image filenames\n",
    "        self.image_filenames = [f for f in os.listdir(images_dir) \n",
    "                               if f.lower().endswith(('.png'))]\n",
    "        self.image_filenames.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load target mask\n",
    "        target_name = img_name.replace('.png', '_trainId.png')\n",
    "        target_path = os.path.join(self.targets_dir, target_name)\n",
    "        target = Image.open(target_path)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "       # else:\n",
    "       #     # Default: convert to tensor\n",
    "       #     target = torch.from_numpy(target)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3a3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"syn_resized_images\"\n",
    "path_target = \"syn_resized_gt\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466)), # We maintain the og aspect ratio\n",
    "    transforms.ToTensor(),  # Converts PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet parameters\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 466), interpolation=Image.NEAREST), # This interpolation ensure that all pixels have a correct value of their class\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "])\n",
    "syn_dataset = SegmentationDataset(images_dir=path_images, targets_dir=path_target, image_transform=image_transform, target_transform=target_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b38de15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 12500\n",
      "Train size: 7500 (60.0%)\n",
      "Validation size: 1250 (10.0%)\n",
      "Test size: 3750 (30.0%)\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 938\n",
      "Validation batches: 157\n",
      "Test batches: 469\n"
     ]
    }
   ],
   "source": [
    "# Get total dataset size\n",
    "total_size = len(syn_dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "# Calculate split sizes (60% train, 10% val, 30% test)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"Validation size: {val_size} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"Test size: {test_size} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "# Create random splits\n",
    "syn_train_dataset, syn_val_dataset, syn_test_dataset = random_split(\n",
    "    syn_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "syn_train_dataloader = DataLoader(\n",
    "    syn_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED) \n",
    ")\n",
    "\n",
    "\n",
    "syn_val_dataloader = DataLoader(\n",
    "    syn_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "syn_test_dataloader = DataLoader(\n",
    "    syn_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    #num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(syn_train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(syn_val_dataloader)}\")\n",
    "print(f\"Test batches: {len(syn_test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0febcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=0.1, ignore_index=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: (N, C, H, W) - logits (non softmaxati)\n",
    "        targets: (N, H, W)   - ground truth con classi (0...C-1)\n",
    "        \"\"\"\n",
    "        num_classes = inputs.shape[1]\n",
    "        device = inputs.device  # Get device from input tensor\n",
    "        \n",
    "        # Softmax sulle predizioni\n",
    "        probs = F.softmax(inputs, dim=1)  # (N, C, H, W)\n",
    "        \n",
    "        # Handle ignore_index by creating a mask and filtering out ignored pixels\n",
    "        if self.ignore_index is not None:\n",
    "            # Create mask for valid pixels\n",
    "            valid_mask = (targets != self.ignore_index)  # (N, H, W)\n",
    "            \n",
    "            # Only process valid pixels\n",
    "            valid_targets = targets[valid_mask]  # (N_valid,)\n",
    "            \n",
    "            # Reshape probs to match and filter valid pixels\n",
    "            probs_reshaped = probs.permute(0, 2, 3, 1)  # (N, H, W, C)\n",
    "            valid_probs = probs_reshaped[valid_mask]  # (N_valid, C)\n",
    "            \n",
    "        else:\n",
    "            # No ignore_index, process all pixels\n",
    "            valid_targets = targets.view(-1)  # (N*H*W,)\n",
    "            valid_probs = probs.permute(0, 2, 3, 1).contiguous().view(-1, num_classes)  # (N*H*W, C)\n",
    "        \n",
    "        # One-hot encoding of valid targets only\n",
    "        if len(valid_targets) > 0:\n",
    "            targets_one_hot = F.one_hot(valid_targets, num_classes=num_classes).float()  # (N_valid, C)\n",
    "        else:\n",
    "            # If no valid pixels, create a zero loss that maintains gradients\n",
    "            # Use a small operation on the input to maintain gradient flow\n",
    "            zero_loss = (inputs * 0.0).sum()  # This maintains gradients from inputs\n",
    "            return zero_loss\n",
    "        \n",
    "        # Calcolo Dice per ogni classe usando solo pixel validi\n",
    "        intersection = (valid_probs * targets_one_hot).sum(dim=0)  # (C,)\n",
    "        union = valid_probs.sum(dim=0) + targets_one_hot.sum(dim=0)  # (C,)\n",
    "        \n",
    "        \n",
    "        smooth_tensor = torch.tensor(self.smooth, device=device, dtype=intersection.dtype)\n",
    "        dice = (2.0 * intersection + smooth_tensor) / (union + smooth_tensor)\n",
    "        \n",
    "        # Media sulle classi\n",
    "        loss = 1.0 - dice.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddedUnet(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', pretrained=True, in_channels=3, num_classes=19, decoder_channels=(128,64,32,16,8)):\n",
    "        super(PaddedUnet, self).__init__()\n",
    "        # Initialize the original UNet model\n",
    "        self.unet = Unet(\n",
    "            backbone=backbone,\n",
    "            pretrained=pretrained,\n",
    "            in_channels=in_channels,\n",
    "            num_classes=num_classes,\n",
    "            decoder_channels=decoder_channels,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Save original dimensions for reference\n",
    "        orig_dim = x.shape[2:]\n",
    "        \n",
    "        # Encoder gives us a list of embeddings, one for each level\n",
    "        embeddings = self.unet.encoder(x)\n",
    "        embeddings.reverse()  # Reverse order to mach decoding \n",
    "        \n",
    "        # Manual decoding with padding fixes\n",
    "        x = embeddings[0]\n",
    "        \n",
    "        for i, block in enumerate(self.unet.decoder.blocks):\n",
    "            # Get skip connection if available\n",
    "            skip = embeddings[i+1] if i+1 < len(embeddings) else None\n",
    "            \n",
    "            # Handle upscaling if needed\n",
    "            if block.scale_factor > 1:\n",
    "                x = F.interpolate(x, scale_factor=block.scale_factor, mode='nearest')\n",
    "            \n",
    "            # Apply padding to match dimensions instead of resizing\n",
    "            # Needed since input shape is not divisible by 32\n",
    "            if skip is not None:\n",
    "                # Check if shapes need adjustment\n",
    "                if x.shape[2:] != skip.shape[2:]:\n",
    "                    # Calculate padding needed\n",
    "                    h_diff = x.shape[2] - skip.shape[2]\n",
    "                    w_diff = x.shape[3] - skip.shape[3]\n",
    "                    \n",
    "                    # Apply padding to match dimensions\n",
    "                    if h_diff > 0 or w_diff > 0:\n",
    "                        # Calculate padding values\n",
    "                        print(f\"Padding skip connection from {skip.shape[2:]} to {x.shape[2:]}\")\n",
    "                        pad_h = (h_diff // 2, h_diff - h_diff // 2)\n",
    "                        pad_w = (w_diff // 2, w_diff - w_diff // 2)\n",
    "                        skip = F.pad(skip, [pad_w[0], pad_w[1], pad_h[0], pad_h[1]])\n",
    "                    elif h_diff < 0 or w_diff < 0:\n",
    "                        # Need to pad the x tensor instead\n",
    "                        print(\"padding tensor\")\n",
    "                        h_diff = -h_diff\n",
    "                        w_diff = -w_diff\n",
    "                        pad_h = (h_diff // 2, h_diff - h_diff // 2)\n",
    "                        pad_w = (w_diff // 2, w_diff - w_diff // 2)\n",
    "                        x = F.pad(x, [pad_w[0], pad_w[1], pad_h[0], pad_h[1]])\n",
    "                \n",
    "                # Concatenate skip connection with current features\n",
    "                x = torch.cat([x, skip], dim=1)\n",
    "                \n",
    "            # Apply convolutions\n",
    "            x = block.conv1(x)\n",
    "            x = block.conv2(x)\n",
    "        \n",
    "        # Apply final convolution\n",
    "        x = self.unet.decoder.final_conv(x)\n",
    "        \n",
    "        # Ensure output matches input dimensions if needed\n",
    "        if x.shape[2:] != orig_dim:\n",
    "            x = F.interpolate(x, size=orig_dim, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return {'out': x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999b1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps detected, using no_ssl_verification\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "import urllib.request\n",
    "from contextlib import contextmanager\n",
    "# Disable SSL verification for urllib requests on MacOS\n",
    "# This is a workaround for the \"SSL: CERTIFICATE_VERIFY_FAILED\" error on MacOS\n",
    "@contextmanager\n",
    "def no_ssl_verification():\n",
    "    \"\"\"Temporarily disable SSL verification\"\"\"\n",
    "    old_context = ssl._create_default_https_context\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        ssl._create_default_https_context = old_context\n",
    "        \n",
    "NUM_CLASSES = 19\n",
    "# channels_default=(256, 128, 64, 32, 16)\n",
    "if DEVICE.type == 'mps':\n",
    "    print(\"mps detected, using no_ssl_verification\")\n",
    "    with no_ssl_verification():\n",
    "        model = PaddedUnet(\n",
    "            backbone='resnet50',\n",
    "            pretrained=True,\n",
    "            in_channels=3,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            decoder_channels=(128,64,32,16,8)\n",
    "        )\n",
    "else:\n",
    "    model = PaddedUnet(\n",
    "        backbone='resnet50',\n",
    "        pretrained=True,\n",
    "        in_channels=3,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        decoder_channels=(128,64,32,16,8)\n",
    "    )\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "LR = 1e-4\n",
    "\n",
    "CE_loss = nn.CrossEntropyLoss(ignore_index=255)  # 255 = unlabeled\n",
    "Dice_loss = DiceLoss(smooth=0.1, ignore_index=255)  \n",
    "\n",
    "\n",
    "importance = 0.7\n",
    "\n",
    "def criterion(outputs, targets):\n",
    "    ce_loss = CE_loss(outputs, targets)\n",
    "    dice_loss = Dice_loss(outputs, targets)\n",
    "    return importance * ce_loss + (1 - importance) * dice_loss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddedUnet(\n",
      "  (unet): Unet(\n",
      "    (encoder): FeatureListNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): UnetDecoder(\n",
      "      (center): Identity()\n",
      "      (blocks): ModuleList(\n",
      "        (0): DecoderBlock(\n",
      "          (conv1): Conv2dBnAct(\n",
      "            (conv): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv2dBnAct(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DecoderBlock(\n",
      "          (conv1): Conv2dBnAct(\n",
      "            (conv): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv2dBnAct(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DecoderBlock(\n",
      "          (conv1): Conv2dBnAct(\n",
      "            (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv2dBnAct(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DecoderBlock(\n",
      "          (conv1): Conv2dBnAct(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv2dBnAct(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (4): DecoderBlock(\n",
      "          (conv1): Conv2dBnAct(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv2dBnAct(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_conv): Conv2d(16, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds, labels, num_classes, ignore_index=255):\n",
    "    \n",
    "    preds = torch.argmax(preds, dim=1).detach().cpu()  # [B, H, W]\n",
    "    \n",
    "    labels = labels.detach().cpu() \n",
    "    \n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (labels == cls)\n",
    "        \n",
    "        # Escludi pixel ignorati\n",
    "        mask = (labels != ignore_index)\n",
    "        pred_inds = pred_inds & mask\n",
    "        target_inds = target_inds & mask\n",
    "\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        \n",
    "        if union == 0:\n",
    "            continue  # salta classe non presente\n",
    "        ious.append(intersection / union)\n",
    "    \n",
    "    if len(ious) == 0:\n",
    "        return float('nan')  # o 0.0 se preferisci\n",
    "    return sum(ious) / len(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc82467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_epoch(model, train_dataloader, val_dataloader, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Train for one epoch and validate on validation set with memory management\n",
    "    Returns: train_loss, train_iou, val_loss, val_iou\n",
    "    \"\"\"\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_total_loss = 0\n",
    "    train_total_iou = 0\n",
    "    \n",
    "    for i, (images, masks) in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)['out']\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect metrics (detach to prevent graph retention)\n",
    "        train_total_loss += loss.detach().cpu().item()\n",
    "        iou_value = compute_iou(outputs.detach().cpu(), masks, NUM_CLASSES)\n",
    "        train_total_iou += iou_value\n",
    "        \n",
    "        # Explicit cleanup of tensors to prevent memory leaks\n",
    "        del images, masks, outputs, loss\n",
    "        \n",
    "        # Periodically clear memory (every 5 batches)\n",
    "        if (i + 1) % 5 == 0:\n",
    "            clear_memory()  \n",
    "    \n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    train_avg_loss = train_total_loss / len(train_dataloader)\n",
    "    train_avg_iou = train_total_iou / len(train_dataloader)\n",
    "    \n",
    "    # Validation \n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    val_total_iou = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(tqdm(val_dataloader, desc=\"Validating\")):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Collect metrics\n",
    "            val_total_loss += loss.detach().cpu().item()\n",
    "            val_total_iou += compute_iou(outputs.detach().cpu(), masks, NUM_CLASSES)\n",
    "            \n",
    "            # Explicit cleanup\n",
    "            del images, masks, outputs, loss\n",
    "            \n",
    "            # Periodic memory clear\n",
    "            if (i + 1) % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    val_avg_loss = val_total_loss / len(val_dataloader)\n",
    "    val_avg_iou = val_total_iou / len(val_dataloader)\n",
    "    \n",
    "    return train_avg_loss, train_avg_iou, val_avg_loss, val_avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Clear memory and cache for all device types\"\"\"\n",
    "    # Delete all local variables in the caller's frame\n",
    "    for obj in list(locals().values()):\n",
    "        del obj\n",
    "        \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if DEVICE.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    # Second GC run to make sure everything is cleaned up\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026bdff",
   "metadata": {},
   "source": [
    " # Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Store metrics for plotting\n",
    "train_losses = []\n",
    "train_ious = []\n",
    "val_losses = []\n",
    "val_ious = []\n",
    "\n",
    "# Track best validation IoU for saving best model\n",
    "best_val_iou = 0.0\n",
    "start = time.time()\n",
    "\n",
    "set_seeds(SEED)\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    # Train and validate in one go\n",
    "    train_loss, train_iou, val_loss, val_iou = train_and_validate_epoch(\n",
    "        model, syn_train_dataloader, syn_val_dataloader, optimizer, criterion\n",
    "    )\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_ious.append(train_iou)\n",
    "    val_losses.append(val_loss)\n",
    "    val_ious.append(val_iou)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train IoU: {train_iou:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val IoU: {val_iou:.4f}\")\n",
    "    \n",
    "    # Save checkpoint after each epoch\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_iou\": train_iou,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_iou\": val_iou,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_ious\": train_ious,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"val_ious\": val_ious,\n",
    "        \"num_classes\": NUM_CLASSES,\n",
    "        \"learning_rate\": LR,\n",
    "    }\n",
    "    \n",
    "    # Save best model based on validation IoU\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        best_model_path = \"models/unet_imagenet1k_Dchannelsx0,5_best_model.pth\"\n",
    "        torch.save(checkpoint, best_model_path)\n",
    "        print(f\"New best model saved: {best_model_path} (Val IoU: {val_iou:.4f})\")\n",
    "    \n",
    "    checkpoint_path = f\"models/unet_imagenet1k_Dchannelsx0,5_epoch_{epoch+1}.pth\"\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "    # Delete old checkpoints if they exist\n",
    "    checkpoint_delete = f\"models/unet_imagenet1k_Dchannelsx0,5_epoch_{epoch}.pth\"\n",
    "    if os.path.exists(checkpoint_delete):\n",
    "        os.remove(checkpoint_delete)\n",
    "        print(f\"Deleted old checkpoint: {checkpoint_delete}\")\n",
    "    \n",
    "    del checkpoint \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nTraining completed in {end - start:.2f} seconds, with {epochs} epochs.\")\n",
    "print(f\"Best validation IoU: {best_val_iou:.4f}\")\n",
    "print(f\"Final model saved as: models/unet_imagenet1k_Dchannelsx0,5_epoch_{epochs}.pth\")\n",
    "print(f\"Best model saved as: models/unet_imagenet1k_Dchannelsx0,5_best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606a1a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dbc7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color map for segmentation (using Cityscapes colors)\n",
    "from cityscapesscripts.helpers import labels as cs_labels\n",
    "def visualize_segmentation(model, dataloader, num_samples=4):\n",
    "    \"\"\"\n",
    "    Visualize segmentation results from the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    images, targets = next(iter(dataloader))\n",
    "    images = images.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)['out']\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    # Move to CPU for visualization\n",
    "    images = images.cpu()\n",
    "    targets = targets.cpu()\n",
    "    predictions = predictions.cpu()\n",
    "    \n",
    "\n",
    "    \n",
    "    def apply_color_map(seg_map):\n",
    "        \"\"\"Apply color mapping to segmentation map\"\"\"\n",
    "        colored_map = np.zeros((seg_map.shape[0], seg_map.shape[1], 3), dtype=np.uint8)\n",
    "        \n",
    "        # Get valid labels (excluding ignore classes)\n",
    "        valid_labels = [label for label in cs_labels.labels if label.trainId != 255 and label.trainId != -1]\n",
    "        \n",
    "        for label in valid_labels:\n",
    "            mask = seg_map == label.trainId\n",
    "            colored_map[mask] = label.color\n",
    "            \n",
    "        return colored_map\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 4))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Original image\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        gt_colored = apply_color_map(targets[i].numpy())\n",
    "        axes[i, 1].imshow(gt_colored)\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        pred_colored = apply_color_map(predictions[i].numpy())\n",
    "        axes[i, 2].imshow(pred_colored)\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ceef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics_from_checkpoint(epochs):\n",
    "    \"\"\"Plot training and validation loss and IoU over epochs from a checkpoint file\"\"\"\n",
    "\n",
    "    checkpoint_path = f\"models/unet_imagenet1k_Dchannelsx0,5_epoch_{epochs}.pth\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "        return\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    train_losses = checkpoint.get('train_losses', [])\n",
    "    val_losses = checkpoint.get('val_losses', [])\n",
    "    train_ious = checkpoint.get('train_ious', [])\n",
    "    val_ious = checkpoint.get('val_ious', [])\n",
    "\n",
    "    if not train_losses or not val_losses or not train_ious or not val_ious:\n",
    "        print(\"No training metrics found in checkpoint.\")\n",
    "        return\n",
    "\n",
    "    epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    ax1.plot(epochs_range, train_losses, 'b-', label='Training Loss', marker='o')\n",
    "    ax1.plot(epochs_range, val_losses, 'r-', label='Validation Loss', marker='s')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot IoU\n",
    "    ax2.plot(epochs_range, train_ious, 'b-', label='Training IoU', marker='o')\n",
    "    ax2.plot(epochs_range, val_ious, 'r-', label='Validation IoU', marker='s')\n",
    "    ax2.set_title('Training and Validation IoU')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('IoU')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"=== TRAINING SUMMARY ===\")\n",
    "    print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "    print(f\"Final Training IoU: {train_ious[-1]:.4f}\")\n",
    "    print(f\"Final Validation IoU: {val_ious[-1]:.4f}\")\n",
    "    print(f\"Best Validation IoU: {max(val_ious):.4f} (Epoch {val_ious.index(max(val_ious)) + 1})\")\n",
    "    print(f\"Best Training IoU: {max(train_ious):.4f} (Epoch {train_ious.index(max(train_ious)) + 1})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edecc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics_from_checkpoint(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbff46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics_from_checkpoint(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"models/unet_imagenet1k_Dchannelsx0,5_best_model.pth\"\n",
    "# Load the best model from checkpoint\n",
    "if os.path.exists(best_model_path):\n",
    "    checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Best model loaded from {best_model_path}\")\n",
    "\n",
    "print(\"Visualizing segmentation results on validation set:\")\n",
    "visualize_segmentation(model, syn_val_dataloader, num_samples=5)\n",
    "print(\"Visualizing segmentation results on training set:\")\n",
    "visualize_segmentation(model, syn_train_dataloader, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
